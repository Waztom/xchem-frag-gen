# -*- coding: utf-8 -*-
"""
Created on Wed Mar 18 16:58:10 2020

@author: Warren Thompson (Waztom)

Classification of COVID data
"""
import rdkit_utils
import os
import requests
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score, train_test_split
from sklearn.metrics import precision_recall_fscore_support  
import joblib
import seaborn as sn

        
# Read preapared csv files generated by SQL.py
script_dir = os.path.dirname(os.path.abspath("__file__"))
rel_path = "Data/All_libraries_filtered.xlsx"
abs_file_path = os.path.join(script_dir, rel_path)

miss_df = pd.read_excel(abs_file_path, sheet_name='Misses')

# Get rid of duplicate values
miss_df = miss_df.drop_duplicates(subset='CompoundSMILES', keep="first")

# Keep only SMILES column
miss_df = miss_df[['CompoundSMILES']]

# Add site classification column where 0 means no hit
miss_df['Site_No'] = np.zeros(len(miss_df['CompoundSMILES']))

# Get the XChem fragment summary
rel_path = "Data/XChem_summary.xlsx"
abs_file_path = os.path.join(script_dir, rel_path)

try:
    hit_df = pd.read_excel(abs_file_path)
except:
    dls = 'https://www.diamond.ac.uk/dam/jcr:cb44b3b1-fb14-4376-b172-ce45cbd66b48/Mpro%20full%20XChem%20screen%20-%20hits%20summary%20-%20ver-2020-03-25.xlsx'   
    resp = requests.get(dls)
    with open('Data/XChem_summary.xlsx', 'wb') as output:
        output.write(resp.content)
        hit_df = pd.read_excel(abs_file_path)

# We only need the SMILES and site info columns
hit_df = hit_df[['Compound SMILES', 'Site']]

# Rename site and Compound SMILES columns for easier merge
hit_df = hit_df.rename(columns={"Site": "Site_No"}) 
hit_df = hit_df.rename(columns={"Compound SMILES": "CompoundSMILES"}) 

# Let's assign active site hits value one and rest 0
active_sites_filter = "active"
hit_df.loc[hit_df.Site_No.str.contains(active_sites_filter)==True, 'Site_No'] = 1
hit_df.loc[hit_df.Site_No.str.contains(active_sites_filter)==False, 'Site_No'] = 0

# Save the hit_df for use in enumerated.py
rel_path = "Data/hits.csv"
abs_file_path = os.path.join(script_dir, rel_path)
hit_df.to_csv(abs_file_path)

# Before we merge, get rid of duplicate entries in hit and miss dfs
hit_SMILES = [SMILES for SMILES in hit_df.CompoundSMILES]
miss_df = miss_df[~miss_df['CompoundSMILES'].isin(hit_SMILES)]
        
# Let's merge the hit and miss dfs for modelling
df = pd.merge(hit_df, miss_df, how='outer')

# Produce rdkit features from SMILES
df,properties = rdkit_utils.get_rdkit_properties(df)

# Get X, y and training and test data
y = df['Site_No']
X = df.drop(columns=['CompoundSMILES', 'Site_No'])

X_train, X_test, y_train, y_test = train_test_split(X, 
                                                    y, 
                                                    test_size=0.33, 
                                                    shuffle=True)

'''
'Let's create a RF model instance. Seed to see same results. High trees to
try avoid OF 
'''
rf_model   = RandomForestClassifier(n_estimators=50000, 
                                    max_features = 8, 
                                    max_depth = 5, 
                                    min_samples_leaf=2)

# Do some CV of the modelrel_path = "Data/hits.csv"
abs_file_path = os.path.join(script_dir, rel_path)
hit_df.to_csv(abs_file_path)
cv_scores = cross_val_score(rf_model, X_train, y_train, cv=10)

# What's the accuracy of our model?
print("Accuracy: {0:0.2f} [Standard {1}]".format(cv_scores.mean(), 
                                                 rf_model.__class__.__name__))

# Train the model
rf_model.fit(X_train,y_train)

# Predictions test
y_pred = rf_model.predict(X_test)

# Make a df to create a confusion matrix
df_model = pd.DataFrame(columns=['y_Actual','y_Predicted'])
df_model['y_Actual'] = y_test
df_model['y_Predicted'] = y_pred

# Create confusion matrix
confusion_matrix = pd.crosstab(df_model['y_Actual'], 
                               df_model['y_Predicted'], 
                               rownames=['Actual'], 
                               colnames=['Predicted'], 
                               margins = True)

# Plot confusion matrix
sn.heatmap(confusion_matrix, annot=True)

# Get the model's precision and recall
scores = precision_recall_fscore_support(y_test, y_pred, average='macro')
print("\nPrecsion score: {0:.2f}\nAccuracy score: {1:.2f}\nF1 score: {2:.2f}\n".format(scores[0],scores[1],scores[2]))

# Get the strength of the RF model's feature importance
for name,model_importance in zip(properties.GetPropertyNames(), rf_model.feature_importances_):
    print("Model importance: {0:.2f} for property: {1}".format(model_importance, name))

# Save the model
rel_path = "Models/RF_model.pkl"
abs_file_path = os.path.join(script_dir, rel_path)
joblib.dump(rf_model, abs_file_path, compress=9)

 